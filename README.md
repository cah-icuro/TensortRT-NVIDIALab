# TensortRT-NVIDIALab

Slide walkthrough: https://drive.google.com/file/d/16ofoa3G5h719ue3f9mdShSTz5g4eBtiu/view

<br />

### Questions

1) We calibrate the INT8 net by minimizing the QL divergence, but how do we interpret a neural network's classifications as a probability distribution rather than a deterministic process?  I think the answer to this lies in answering 2.

2) In the diagram on slide 42, what is the meaning of X and Y axes?

3) Why is "pad" a parameter for a convolutional layer?  What would it mean to select a value other than (kernel_size-1)/2 ?

